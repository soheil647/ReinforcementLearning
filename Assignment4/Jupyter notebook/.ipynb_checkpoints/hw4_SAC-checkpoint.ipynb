{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPhlR11+szj1RIgCVZzHuy9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Introduction\n","In homework assignment 3, we will implement the soft actor critic (SAC) algorithm to solve a classic rocket trajectory optimization problem--Lunar Lander v2"],"metadata":{"id":"t1is6vkA-xft"}},{"cell_type":"markdown","source":["# Enabling and testing the GPU\n","\n","First, you may need to enable GPUs for this notebook:\n","\n","- Navigate to Editâ†’Notebook Settings\n","- select GPU from the Hardware Accelerator drop-down\n","\n","Next, we'll confirm that we can connect to the GPU with pytorch:"],"metadata":{"id":"alkW3ftVoWtP"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"U1dz4RWKoPsa"},"outputs":[],"source":["import torch\n","import os\n","if torch.cuda.is_available():\n","    os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n","    device = torch.device('cuda:0')\n","else:\n","    device = torch.device('cpu')\n","print('Found device at: {}'.format(device))"]},{"cell_type":"markdown","source":["#Install gym environment"],"metadata":{"id":"uwoy9e6Joqxi"}},{"cell_type":"code","source":["!pip install swig\n","!pip install gymnasium[box2d]"],"metadata":{"id":"BpRIObiAosUM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Load tensorboard for visualizing"],"metadata":{"id":"2JhYhit3ouxs"}},{"cell_type":"code","source":["%load_ext tensorboard"],"metadata":{"id":"nufSmh6Ao7SV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Import required package"],"metadata":{"id":"f6MHnRjKpBnD"}},{"cell_type":"code","source":["import torch.nn as nn\n","from math import pi as pi_constant\n","from typing import Tuple\n","from collections import namedtuple\n","from collections import deque\n","import numpy.random as nr\n","\n","import numpy as np\n","import gymnasium as gym\n","from torch.utils.tensorboard import SummaryWriter\n","\n","import datetime\n","import copy\n","\n","Tensor = torch.DoubleTensor\n","torch.set_default_tensor_type(Tensor)\n","Transitions = namedtuple('Transitions', ['obs', 'action', 'reward', 'next_obs', 'done'])"],"metadata":{"id":"7W8j9M99pC6r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Replay buffer"],"metadata":{"id":"gZ7vM61mpcFT"}},{"cell_type":"code","source":["class ReplayBuffer(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        replay_buffer_size = config['replay_buffer_size']\n","        seed = config['seed']\n","        self.device = config['device']\n","        nr.seed(seed)\n","\n","        self.replay_buffer_size = replay_buffer_size\n","        self.obs = deque([], maxlen=self.replay_buffer_size)\n","        self.action = deque([], maxlen=self.replay_buffer_size)\n","        self.reward = deque([], maxlen=self.replay_buffer_size)\n","        self.next_obs = deque([], maxlen=self.replay_buffer_size)\n","        self.done = deque([], maxlen=self.replay_buffer_size)\n","\n","    def append_memory(self,\n","                      obs,\n","                      action,\n","                      reward,\n","                      next_obs,\n","                      done: bool):\n","        self.obs.append(obs)\n","        self.action.append(action)\n","        self.reward.append(reward)\n","        self.next_obs.append(next_obs)\n","        self.done.append(done)\n","\n","    def sample(self, batch_size):\n","        buffer_size = len(self.obs)\n","\n","        idx = nr.choice(buffer_size,\n","                        size=min(buffer_size, batch_size),\n","                        replace=False)\n","        t = Transitions\n","        t.obs = torch.stack(list(map(self.obs.__getitem__, idx))).to(self.device)\n","        t.action = torch.stack(list(map(self.action.__getitem__, idx))).to(self.device)\n","        t.reward = torch.stack(list(map(self.reward.__getitem__, idx))).to(self.device)\n","        t.next_obs = torch.stack(list(map(self.next_obs.__getitem__, idx))).to(self.device)\n","        t.done = torch.tensor(list(map(self.done.__getitem__, idx)))[:, None].to(self.device)\n","        return t\n","\n","    def clear(self):\n","        self.obs = deque([], maxlen=self.replay_buffer_size)\n","        self.action = deque([], maxlen=self.replay_buffer_size)\n","        self.reward = deque([], maxlen=self.replay_buffer_size)\n","        self.next_obs = deque([], maxlen=self.replay_buffer_size)\n","        self.done = deque([], maxlen=self.replay_buffer_size)"],"metadata":{"id":"m8oZcmTKpb4Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Actor network"],"metadata":{"id":"o5kaGexLpiTq"}},{"cell_type":"code","source":["class ActorNet(nn.Module):\n","    def __init__(self,\n","                 device,\n","                 dim_obs: int,\n","                 dim_action: int,\n","                 dims_hidden_neurons: Tuple[int] = (64, 64)):\n","        super(ActorNet, self).__init__()\n","        self.n_layers = len(dims_hidden_neurons)\n","        self.dim_action = dim_action\n","        self.device = device\n","\n","        self.ln2pi = torch.log(Tensor([2*pi_constant]))\n","\n","        n_neurons = (dim_obs,) + dims_hidden_neurons + (dim_action,)\n","        for i, (dim_in, dim_out) in enumerate(zip(n_neurons[:-2], n_neurons[1:-1])):\n","            layer = nn.Linear(dim_in, dim_out).double()\n","            # nn.Linear: input: (batch_size, n_feature)\n","            #            output: (batch_size, n_output)\n","            torch.nn.init.xavier_uniform_(layer.weight)\n","            torch.nn.init.zeros_(layer.bias)\n","            exec('self.layer{} = layer'.format(i + 1))  # exec(str): execute a short program written in the str\n","\n","        self.output_mu = nn.Linear(n_neurons[-2], n_neurons[-1]).double()\n","        torch.nn.init.xavier_uniform_(self.output_mu.weight)\n","        torch.nn.init.zeros_(self.output_mu.bias)\n","\n","        self.output_logsig = nn.Linear(n_neurons[-2], n_neurons[-1]).double()\n","        torch.nn.init.xavier_uniform_(self.output_logsig.weight)\n","        torch.nn.init.zeros_(self.output_logsig.bias)\n","\n","    def forward(self, obs: torch.Tensor):\n","        x = obs\n","        for i in range(self.n_layers):\n","            x = eval('torch.relu(self.layer{}(x))'.format(i + 1))\n","        mu = self.output_mu(x)\n","        sig = torch.exp(self.output_logsig(x))\n","\n","        # for the log probability under tanh-squashed Gaussian, see Appendix C of the SAC paper\n","        u = mu + sig * torch.normal(torch.zeros(size=mu.shape), 1).to(self.device)\n","        a = torch.tanh(u)\n","        logProbu = -1/2 * (torch.sum(torch.log(sig**2), dim=1, keepdims=True).to(self.device) +\n","                           torch.sum((u-mu)**2/sig**2, dim=1, keepdims=True) +\n","                           a.shape[1]*self.ln2pi.to(self.device))\n","        logProba = logProbu - torch.sum(torch.log(1 - a ** 2 + 0.000001), dim=1, keepdims=True)\n","        return a, logProba, torch.tanh(mu)"],"metadata":{"id":"S_hd5RvBpiwl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Critic network"],"metadata":{"id":"f8QH0vsKpt-f"}},{"cell_type":"code","source":["class QCriticNet(nn.Module):\n","    def __init__(self,\n","                 dim_obs: int,\n","                 dim_action: int,\n","                 dims_hidden_neurons: Tuple[int] = (64, 64)):\n","        super(QCriticNet, self).__init__()\n","        self.n_layers = len(dims_hidden_neurons)\n","        self.dim_action = dim_action\n","\n","        n_neurons = (dim_obs + dim_action,) + dims_hidden_neurons + (1,)\n","        for i, (dim_in, dim_out) in enumerate(zip(n_neurons[:-2], n_neurons[1:-1])):\n","            layer = nn.Linear(dim_in, dim_out).double()\n","            # nn.Linear: input: (batch_size, n_feature)\n","            #            output: (batch_size, n_output)\n","            torch.nn.init.xavier_uniform_(layer.weight)\n","            torch.nn.init.zeros_(layer.bias)\n","            exec('self.layer{} = layer'.format(i + 1))  # exec(str): execute a short program written in the str\n","\n","        self.output = nn.Linear(n_neurons[-2], n_neurons[-1]).double()\n","        torch.nn.init.xavier_uniform_(self.output.weight)\n","        torch.nn.init.zeros_(self.output.bias)\n","\n","    def forward(self, obs: torch.Tensor, action: torch.Tensor):\n","        x = torch.cat((obs, action), dim=1)\n","        for i in range(self.n_layers):\n","            x = eval('torch.relu(self.layer{}(x))'.format(i + 1))\n","        return self.output(x)"],"metadata":{"id":"Ti89wwV0pugP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#SAC agent\n","The base code are given in this section. The updates of the actor and critic networks are missing and are left out for you to fill. You may refer to the SAC paper https://arxiv.org/pdf/1801.01290.pdf or Spinning up tutorial for SAC https://spinningup.openai.com/en/latest/algorithms/sac.html"],"metadata":{"id":"1rV9DcRZpyKm"}},{"cell_type":"code","source":["class SAC(nn.Module):\n","    def __init__(self, config):\n","        super(SAC,self).__init__()\n","        torch.manual_seed(config['seed'])\n","\n","        self.lr = config['lr']  # learning rate\n","        self.smooth = config['smooth']  # smoothing coefficient for target net\n","        self.discount = config['discount']  # discount factor\n","        self.alpha = config['alpha']  # temperature parameter in SAC\n","        self.batch_size = config['batch_size']  # mini batch size\n","\n","        self.dims_hidden_neurons = config['dims_hidden_neurons']\n","        self.dim_obs = config['dim_obs']\n","        self.dim_action = config['dim_action']\n","\n","        self.device = config['device']\n","\n","        self.actor = ActorNet(device=config['device'],\n","                              dim_obs=self.dim_obs,\n","                              dim_action=self.dim_action,\n","                              dims_hidden_neurons=self.dims_hidden_neurons).to(self.device)\n","        self.Q1 = QCriticNet(dim_obs=self.dim_obs,\n","                             dim_action=self.dim_action,\n","                             dims_hidden_neurons=self.dims_hidden_neurons).to(self.device)\n","        self.Q2 = QCriticNet(dim_obs=self.dim_obs,\n","                             dim_action=self.dim_action,\n","                             dims_hidden_neurons=self.dims_hidden_neurons).to(self.device)\n","        self.Q1_tar = QCriticNet(dim_obs=self.dim_obs,\n","                                 dim_action=self.dim_action,\n","                                 dims_hidden_neurons=self.dims_hidden_neurons).to(self.device)\n","        self.Q2_tar = QCriticNet(dim_obs=self.dim_obs,\n","                                 dim_action=self.dim_action,\n","                                 dims_hidden_neurons=self.dims_hidden_neurons).to(self.device)\n","\n","        self.optimizer_actor = torch.optim.Adam(self.actor.parameters(), lr=self.lr)\n","        self.optimizer_Q1 = torch.optim.Adam(self.Q1.parameters(), lr=self.lr)\n","        self.optimizer_Q2 = torch.optim.Adam(self.Q2.parameters(), lr=self.lr)\n","\n","    def update(self, buffer):\n","        # sample from replay memory\n","        t = buffer.sample(self.batch_size)\n","\n","        # TO DO: Perform the updates for the actor and critic networks\n","        \n","\n","    def act_probabilistic(self, obs: torch.Tensor):\n","        self.actor.eval()\n","        a, logProb, mu = self.actor(obs)\n","        self.actor.train()\n","        return a\n","\n","    def act_deterministic(self, obs: torch.Tensor):\n","        self.actor.eval()\n","        a, logProb, mu = self.actor(obs)\n","        self.actor.train()\n","        return mu"],"metadata":{"id":"kibmQMdfp0hI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Create environment"],"metadata":{"id":"V5a5F5dUqNVp"}},{"cell_type":"code","source":["env = gym.make('LunarLanderContinuous-v2')\n","\n","config = {\n","    'dim_obs': 8,\n","    'dim_action': 2,\n","    'dims_hidden_neurons': (120, 120),\n","    'lr': 0.001,\n","    'smooth': 0.99,\n","    'discount': 0.99,\n","    'alpha': 0.2,\n","    'batch_size': 128,\n","    'replay_buffer_size': 20000,\n","    'seed': 1,\n","    'max_episode': 500,\n","    'device':device\n","}"],"metadata":{"id":"akZVhny6qPtK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Create agent"],"metadata":{"id":"206NmhcDqQPm"}},{"cell_type":"code","source":["sac = SAC(config).to(device)\n","buffer = ReplayBuffer(config)\n","train_writer = SummaryWriter(log_dir='tensorboard/sac')"],"metadata":{"id":"0ms3ASqIqR56"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Start training"],"metadata":{"id":"UzX9HDv8qXTG"}},{"cell_type":"code","source":["steps = 0\n","for i_episode in range(config['max_episode']):\n","    obs = env.reset()[0]\n","    done = False\n","    truncated = False\n","    t = 0\n","    ret = 0.\n","    while done is False and truncated is False:\n","        # env.render()\n","\n","        obs_tensor = torch.tensor(obs).type(Tensor).to(device)\n","\n","        action = sac.act_probabilistic(obs_tensor[None, :]).detach().cpu().numpy()[0, :]\n","        next_obs, reward, done, truncated,_ = env.step(action)\n","\n","        buffer.append_memory(obs=obs_tensor,\n","                             action=torch.from_numpy(action),\n","                             reward=torch.from_numpy(np.array([reward/10.0])),\n","                             next_obs=torch.from_numpy(next_obs).type(Tensor),\n","                             done=done)\n","\n","        sac.update(buffer)\n","\n","        t += 1\n","        steps += 1\n","        ret += reward\n","\n","        obs = copy.deepcopy(next_obs)\n","\n","        if done or truncated:\n","            print(\"Episode {} return {}\".format(i_episode, ret))\n","    train_writer.add_scalar('Performance/episodic_return', ret, i_episode)\n","\n","env.close()\n","train_writer.close()"],"metadata":{"id":"4gtDa5MFqdFI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#visualizing"],"metadata":{"id":"wRX9rXK8qfH3"}},{"cell_type":"code","source":["%tensorboard --logdir='tensorboard/sac'"],"metadata":{"id":"wGkuWln6qjci"},"execution_count":null,"outputs":[]}]}